{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eb9b9c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19b5d1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "class Att_UNet():\n",
    "    def __init__(self, list_predictors, list_targets, patch_dim, batch_size, n_filters, activation, kernel_initializer, batch_norm, pooling_type, dropout):\n",
    "        self.list_predictors = list_predictors\n",
    "        self.list_targets = list_targets\n",
    "        self.patch_dim = patch_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_filters = n_filters\n",
    "        self.activation = activation\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.batch_norm = batch_norm\n",
    "        self.pooling_type = pooling_type\n",
    "        self.dropout = dropout\n",
    "        self.n_predictors = len(list_predictors)\n",
    "    #\n",
    "    def repeat_elem(self, tensor, rep):\n",
    "        return tf.keras.layers.Lambda(lambda x, repnum: tf.keras.backend.repeat_elements(x, repnum, axis = 3), arguments = {'repnum': rep})(tensor)\n",
    "    #\n",
    "    def gating_signal(self, x, n_filters, batch_norm = False):\n",
    "        x = tf.keras.layers.Conv2D(n_filters, (1,1), padding = \"same\")(x)\n",
    "        if batch_norm == True:\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        return(x)\n",
    "    #\n",
    "    def attention_block(self, x, g, inter_shape):\n",
    "        shape_x = tf.keras.backend.int_shape(x)\n",
    "        shape_g = tf.keras.backend.int_shape(g)\n",
    "        #\n",
    "        theta_x = tf.keras.layers.Conv2D(inter_shape, kernel_size = (2,2), strides = (2,2), padding = \"same\")(x) \n",
    "        shape_theta_x = tf.keras.backend.int_shape(theta_x)\n",
    "        #\n",
    "        phi_g = tf.keras.layers.Conv2D(inter_shape, kernel_size = (1,1), padding = \"same\")(g)\n",
    "        upsample_g = tf.keras.layers.Conv2DTranspose(inter_shape, (3,3), \n",
    "                                                     strides = (shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
    "                                                     padding = \"same\")(phi_g)\n",
    "        \n",
    "        concat_xg = tf.keras.layers.add([upsample_g, theta_x])\n",
    "        act_xg = tf.keras.layers.Activation(\"relu\")(concat_xg)\n",
    "        #\n",
    "        psi = tf.keras.layers.Conv2D(1, (1,1), padding = \"same\")(act_xg)\n",
    "        sigmoid_xg = tf.keras.layers.Activation(\"sigmoid\")(psi)\n",
    "        shape_sigmoid = tf.keras.backend.int_shape(sigmoid_xg)\n",
    "        #\n",
    "        upsample_psi = tf.keras.layers.UpSampling2D(size = (shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)\n",
    "        upsample_psi = self.repeat_elem(upsample_psi, shape_x[3])\n",
    "        y = tf.keras.layers.multiply([upsample_psi, x])\n",
    "        #\n",
    "        result = tf.keras.layers.Conv2D(shape_x[3], (1,1), padding = \"same\")(y)\n",
    "        result_bn = tf.keras.layers.BatchNormalization()(result)\n",
    "        #\n",
    "        return(result_bn)\n",
    "    #\n",
    "    def conv_block(self, x, n_filters, padding = \"same\"):\n",
    "        x = tf.keras.layers.Conv2D(n_filters, kernel_size = (3,3), padding = padding, kernel_initializer = self.kernel_initializer)(x)\n",
    "        if self.batch_norm == True:\n",
    "            x = tf.keras.layers.BatchNormalization(axis = 3)(x)\n",
    "        x = tf.keras.layers.Activation(self.activation)(x)\n",
    "        #\n",
    "        x = tf.keras.layers.Conv2D(n_filters, kernel_size = (3,3), padding = padding, kernel_initializer = self.kernel_initializer)(x)\n",
    "        if self.batch_norm == True:\n",
    "            x = tf.keras.layers.BatchNormalization(axis = 3)(x)\n",
    "        x = tf.keras.layers.Activation(self.activation)(x)\n",
    "        #\n",
    "        return(x)\n",
    "    #\n",
    "    def downsample_block(self, x, n_filters, pool_size = (2,2), strides = 2):\n",
    "        f = self.conv_block(x, n_filters)\n",
    "        #\n",
    "        if self.pooling_type == \"Max\":\n",
    "            p = tf.keras.layers.MaxPool2D(pool_size = pool_size, strides = strides)(f)\n",
    "        elif self.pooling_type == \"Average\":\n",
    "            p = tf.keras.layers.AveragePooling2D(pool_size = pool_size, strides = strides)(f)\n",
    "        #\n",
    "        p = tf.keras.layers.Dropout(self.dropout)(p)\n",
    "        return(f, p)  \n",
    "    #\n",
    "    def upsample_block(self, x, conv_features, n_filters, kernel_size = (2,2), strides = 2, padding = \"same\"):\n",
    "        gating = self.gating_signal(x, n_filters)\n",
    "        att = self.attention_block(conv_features, gating, n_filters)\n",
    "        up_att = tf.keras.layers.UpSampling2D(size = (2, 2), data_format = \"channels_last\")(x)\n",
    "        up_att = tf.keras.layers.concatenate([up_att, att], axis = 3)\n",
    "        up_conv = self.conv_block(up_att, n_filters)\n",
    "        return(up_conv)\n",
    "    #\n",
    "    def make_unet_model(self): \n",
    "        inputs = tf.keras.layers.Input(shape = (*self.patch_dim, self.n_predictors))\n",
    "        # Encoder (downsample)\n",
    "        f1, p1 = self.downsample_block(inputs, self.n_filters[0])\n",
    "        f2, p2 = self.downsample_block(p1, self.n_filters[1])\n",
    "        f3, p3 = self.downsample_block(p2, self.n_filters[2])\n",
    "        f4, p4 = self.downsample_block(p3, self.n_filters[3])\n",
    "        f5, p5 = self.downsample_block(p4, self.n_filters[4])\n",
    "        # Bottleneck\n",
    "        u5 = self.conv_block(p5, self.n_filters[5])\n",
    "        # Decoder (upsample)\n",
    "        u4 = self.upsample_block(u5, f5, self.n_filters[4])\n",
    "        u3 = self.upsample_block(u4, f4, self.n_filters[3])\n",
    "        u2 = self.upsample_block(u3, f3, self.n_filters[2])\n",
    "        u1 = self.upsample_block(u2, f2, self.n_filters[1])\n",
    "        u0 = self.upsample_block(u1, f1, self.n_filters[0])\n",
    "        # outputs\n",
    "        SIC = tf.keras.layers.Conv2D(1, (1, 1), padding = \"same\", activation = \"linear\", dtype = tf.float32, name = \"SIC\")(u0)\n",
    "        unet_model = tf.keras.Model(inputs, SIC, name = \"U-Net\")\n",
    "        #\n",
    "        return(unet_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
