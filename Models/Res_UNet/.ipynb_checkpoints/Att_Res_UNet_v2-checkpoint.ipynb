{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "class Att_res_UNet():\n",
    "    def __init__(self, list_predictors, list_targets, patch_dim, batch_size, n_filters, activation, kernel_initializer, batch_norm, pooling_type, dropout):\n",
    "        self.list_predictors = list_predictors\n",
    "        self.list_targets = list_targets\n",
    "        self.patch_dim = patch_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.n_filters = n_filters\n",
    "        self.activation = activation\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.batch_norm = batch_norm\n",
    "        self.pooling_type = pooling_type\n",
    "        self.dropout = dropout\n",
    "        self.n_predictors = len(list_predictors)\n",
    "        self.n_targets = len(list_targets)\n",
    "    #\n",
    "    def residual_conv_block(x, n_filters, padding = \"same\"):\n",
    "        conv = tf.keras.layers.Conv2D(n_filters, kernel_size = (3,3), padding = padding, kernel_initializer = self.kernel_initializer)(x)\n",
    "        if self.batch_norm == True:\n",
    "            conv = tf.keras.layers.BatchNormalization(axis = 3)(conv)\n",
    "        conv = tf.keras.layers.Activation(self.activation)(conv)\n",
    "        #\n",
    "        conv = tf.keras.layers.Conv2D(n_filters, kernel_size = (3,3), padding = padding, kernel_initializer = self.kernel_initializer)(conv)\n",
    "        if self.batch_norm == True:\n",
    "            conv = tf.keras.layers.BatchNormalization(axis = 3)(conv)\n",
    "        #\n",
    "        shortcut = tf.keras.layers.Conv2D(n_filters, kernel_size = (1,1), padding = padding)(x)\n",
    "        if self.batch_norm == True:\n",
    "            shortcut = tf.keras.layers.BatchNormalization(axis = 3)(shortcut)\n",
    "        #\n",
    "        res_path = tf.keras.layers.add([shortcut, conv])\n",
    "        res_path = tf.keras.layers.Activation(self.activation)(res_path)\n",
    "        #\n",
    "        return(res_path)\n",
    "    #\n",
    "    def downsample_block(x, n_filters, pool_size = (2,2), strides = 2):\n",
    "        f = residual_conv_block(x, n_filters)\n",
    "        #\n",
    "        if self.pooling_type == \"Max\":\n",
    "            p = tf.keras.layers.MaxPool2D(pool_size = pool_size, strides = strides)(f)\n",
    "        elif self.pooling_type == \"Average\":\n",
    "            p = tf.keras.layers.AveragePooling2D(pool_size = pool_size, strides = strides)(f)\n",
    "        #\n",
    "        p = tf.keras.layers.Dropout(self.dropout)(p)\n",
    "        return(f, p)  \n",
    "    #\n",
    "    def upsample_block(x, conv_features, n_filters, kernel_size = (2,2), strides = 2, padding = \"same\"):\n",
    "        x = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size = kernel_size, strides = strides, padding = padding)(x)\n",
    "        x = tf.keras.layers.concatenate([x, conv_features])\n",
    "        x = tf.keras.layers.Dropout(self.dropout)(x)\n",
    "        x = residual_conv_block(x, n_filters)\n",
    "        return(x)\n",
    "    #\n",
    "    def make_unet_model(): \n",
    "        inputs = tf.keras.layers.Input(shape = (*self.patch_dim, self.n_predictors))\n",
    "        # Encoder (downsample)\n",
    "        f1, p1 = downsample_block(inputs, self.n_filters[0])\n",
    "        f2, p2 = downsample_block(p1, self.n_filters[1])\n",
    "        f3, p3 = downsample_block(p2, self.n_filters[2])\n",
    "        f4, p4 = downsample_block(p3, self.n_filters[3])\n",
    "        f5, p5 = downsample_block(p4, self.n_filters[4])\n",
    "        # Bottleneck\n",
    "        u5 = residual_conv_block(p5, self.n_filters[5])\n",
    "        # Decoder (upsample)\n",
    "        u4 = upsample_block(u5, f5, self.n_filters[4])\n",
    "        u3 = upsample_block(u4, f4, self.n_filters[3])\n",
    "        u2 = upsample_block(u3, f3, self.n_filters[2])\n",
    "        u1 = upsample_block(u2, f2, self.n_filters[1])\n",
    "        u0 = upsample_block(u1, f1, self.n_filters[0])\n",
    "        # outputs\n",
    "        SICerror = tf.keras.layers.Conv2D(1, (1, 1), padding = \"same\", activation = \"linear\", dtype = tf.float32, name = \"SICerror\")(u0)\n",
    "        unet_model = tf.keras.Model(inputs, SICerror, name = \"U-Net\")\n",
    "        #\n",
    "        return(unet_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
